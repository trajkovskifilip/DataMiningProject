{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DataMining_Preprocessing.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "H6yvvxKbQHA6"
      },
      "source": [
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import seaborn as sns\r\n",
        "from sklearn.experimental import enable_iterative_imputer\r\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\r\n",
        "from sklearn.impute import SimpleImputer, IterativeImputer\r\n",
        "from sklearn.neighbors import KNeighborsRegressor\r\n",
        "from sklearn.tree import DecisionTreeRegressor\r\n",
        "from sklearn.ensemble import ExtraTreesRegressor\r\n",
        "from sklearn.linear_model import BayesianRidge\r\n",
        "import pickle\r\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "akr5C3OBin6x"
      },
      "source": [
        "We will use two techniques for handling missing data:\r\n",
        "1. Fill the missing data using an imputer with the best score\r\n",
        "2. If data is missing for more than 3 hours, remove those rows, otherwise linearly interpolate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dfPYt6ynXZgD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f90b0ea-1b6b-43a4-ecf7-012dac815897"
      },
      "source": [
        "df = pd.read_csv('./datasets/Karpos.csv', index_col=0)\r\n",
        "df.drop(['NO2'], axis=1, inplace=True)\r\n",
        "# use the following lines only if you want to interpolate the missing data\r\n",
        "print(\"Number of rows before interpolation: {}\".format(len(df)))\r\n",
        "print(\"Number of NaN rows: {}\".format(df.isna().sum()))\r\n",
        "df = df.interpolate(method=\"linear\", limit=1, limit_area=\"inside\")\r\n",
        "df = df.dropna()\r\n",
        "print(\"Number of rows after interpolation: {}\".format(len(df)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of rows before interpolation: 17904\n",
            "Number of NaN rows: relative_humidity      11\n",
            "wind_speed              0\n",
            "visibility              0\n",
            "pressure               17\n",
            "snow                   13\n",
            "solar_radiation         0\n",
            "wind_direction         11\n",
            "temperature            13\n",
            "precipitation           0\n",
            "cloud_coverage          0\n",
            "hour                    0\n",
            "day                     0\n",
            "month                   0\n",
            "year                    0\n",
            "weekend                 0\n",
            "holiday                 0\n",
            "PM10                 3326\n",
            "PM25                  644\n",
            "SO2                  2329\n",
            "dtype: int64\n",
            "Number of rows after interpolation: 13160\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pf2rupqIQxGI"
      },
      "source": [
        "**Train-validation-test data split**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7UzBHcUPQ36R"
      },
      "source": [
        "train_size = int(0.8 * df.shape[0])\r\n",
        "validation_size = int(0.1 * df.shape[0])\r\n",
        "df_train = df.iloc[:train_size]\r\n",
        "df_validation = df.iloc[train_size:train_size + validation_size]\r\n",
        "df_test = df.iloc[train_size + validation_size:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yZiXHBj5Q3Wp"
      },
      "source": [
        "**Scaling the data**\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_raqxWPGQ9F5"
      },
      "source": [
        "features_to_standardize = ['PM10', 'PM25', 'SO2', 'relative_humidity', 'pressure',\r\n",
        "                           'solar_radiation', 'wind_direction', 'temperature']\r\n",
        "features_to_normalize = ['wind_speed', 'visibility', 'snow', 'precipitation', 'cloud_coverage',\r\n",
        "                         'hour', 'day', 'month', 'year']\r\n",
        "\r\n",
        "scalers = {}\r\n",
        "for feature in features_to_standardize:\r\n",
        "  scaler = StandardScaler()\r\n",
        "  scaler.fit(df_train[feature].values.reshape(-1, 1))\r\n",
        "  scalers[feature] = scaler\r\n",
        "\r\n",
        "for feature in features_to_normalize:\r\n",
        "  scaler = MinMaxScaler()\r\n",
        "  scaler.fit(df_train[feature].values.reshape(-1, 1))\r\n",
        "  scalers[feature] = scaler\r\n",
        "\r\n",
        "for feature, scaler in scalers.items():\r\n",
        "  with open(f'./scalers/Karpos/{feature}', 'wb') as f:\r\n",
        "    pickle.dump(scaler, f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "id": "m4zIM7wRRIMB",
        "outputId": "d7466ddf-68d3-49e3-8778-5a65f5eb29ef"
      },
      "source": [
        "df_train_scaled = df_train.copy()\r\n",
        "df_validation_scaled = df_validation.copy()\r\n",
        "df_test_scaled = df_test.copy()\r\n",
        "for feature, scaler in scalers.items():\r\n",
        "  df_train_scaled[feature] = scaler.transform(df_train[feature].values.reshape(-1, 1)).flatten()\r\n",
        "  df_validation_scaled[feature] = scaler.transform(df_validation[feature].values.reshape(-1, 1)).flatten()\r\n",
        "  df_test_scaled[feature] = scaler.transform(df_test[feature].values.reshape(-1, 1)).flatten()\r\n",
        "\r\n",
        "df_validation_scaled.describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>relative_humidity</th>\n",
              "      <th>wind_speed</th>\n",
              "      <th>visibility</th>\n",
              "      <th>pressure</th>\n",
              "      <th>snow</th>\n",
              "      <th>solar_radiation</th>\n",
              "      <th>wind_direction</th>\n",
              "      <th>temperature</th>\n",
              "      <th>precipitation</th>\n",
              "      <th>cloud_coverage</th>\n",
              "      <th>hour</th>\n",
              "      <th>day</th>\n",
              "      <th>month</th>\n",
              "      <th>year</th>\n",
              "      <th>weekend</th>\n",
              "      <th>holiday</th>\n",
              "      <th>PM10</th>\n",
              "      <th>PM25</th>\n",
              "      <th>SO2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>1316.000000</td>\n",
              "      <td>1316.000000</td>\n",
              "      <td>1316.000000</td>\n",
              "      <td>1316.000000</td>\n",
              "      <td>1316.0</td>\n",
              "      <td>1316.000000</td>\n",
              "      <td>1316.000000</td>\n",
              "      <td>1316.000000</td>\n",
              "      <td>1316.000000</td>\n",
              "      <td>1316.000000</td>\n",
              "      <td>1316.000000</td>\n",
              "      <td>1316.000000</td>\n",
              "      <td>1316.000000</td>\n",
              "      <td>1316.0</td>\n",
              "      <td>1316.000000</td>\n",
              "      <td>1316.0</td>\n",
              "      <td>1316.000000</td>\n",
              "      <td>1316.000000</td>\n",
              "      <td>1316.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>-0.320853</td>\n",
              "      <td>0.265458</td>\n",
              "      <td>0.482776</td>\n",
              "      <td>-0.366892</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.570652</td>\n",
              "      <td>0.122767</td>\n",
              "      <td>1.092187</td>\n",
              "      <td>0.009538</td>\n",
              "      <td>0.355114</td>\n",
              "      <td>0.501454</td>\n",
              "      <td>0.467376</td>\n",
              "      <td>0.479829</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.072948</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.832714</td>\n",
              "      <td>-0.595272</td>\n",
              "      <td>-0.383143</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.936908</td>\n",
              "      <td>0.115307</td>\n",
              "      <td>0.431751</td>\n",
              "      <td>0.669971</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.379757</td>\n",
              "      <td>0.950437</td>\n",
              "      <td>0.625738</td>\n",
              "      <td>0.057940</td>\n",
              "      <td>0.338406</td>\n",
              "      <td>0.301912</td>\n",
              "      <td>0.293298</td>\n",
              "      <td>0.055731</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.260151</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.639086</td>\n",
              "      <td>0.635631</td>\n",
              "      <td>0.542258</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>-2.353560</td>\n",
              "      <td>0.028571</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-1.688309</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.654738</td>\n",
              "      <td>-1.397954</td>\n",
              "      <td>-0.378663</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.363636</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-3.457721</td>\n",
              "      <td>-2.535463</td>\n",
              "      <td>-1.652397</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>-1.105337</td>\n",
              "      <td>0.171429</td>\n",
              "      <td>0.111111</td>\n",
              "      <td>-0.896201</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.654738</td>\n",
              "      <td>-0.594873</td>\n",
              "      <td>0.640070</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.030000</td>\n",
              "      <td>0.260870</td>\n",
              "      <td>0.233333</td>\n",
              "      <td>0.454545</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-1.212325</td>\n",
              "      <td>-0.977607</td>\n",
              "      <td>-0.714036</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>-0.306474</td>\n",
              "      <td>0.257143</td>\n",
              "      <td>0.222222</td>\n",
              "      <td>-0.326557</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.102313</td>\n",
              "      <td>0.157218</td>\n",
              "      <td>1.043086</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.521739</td>\n",
              "      <td>0.433333</td>\n",
              "      <td>0.454545</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.769422</td>\n",
              "      <td>-0.491661</td>\n",
              "      <td>-0.436379</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>0.492389</td>\n",
              "      <td>0.342857</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.037476</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.827367</td>\n",
              "      <td>0.981545</td>\n",
              "      <td>1.546855</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.660000</td>\n",
              "      <td>0.782609</td>\n",
              "      <td>0.700000</td>\n",
              "      <td>0.545455</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.417934</td>\n",
              "      <td>-0.152790</td>\n",
              "      <td>-0.122801</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1.640755</td>\n",
              "      <td>0.685714</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.547539</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.247922</td>\n",
              "      <td>1.661402</td>\n",
              "      <td>2.767096</td>\n",
              "      <td>0.654592</td>\n",
              "      <td>0.990000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.545455</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.801180</td>\n",
              "      <td>0.646321</td>\n",
              "      <td>2.612347</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       relative_humidity   wind_speed  ...         PM25          SO2\n",
              "count        1316.000000  1316.000000  ...  1316.000000  1316.000000\n",
              "mean           -0.320853     0.265458  ...    -0.595272    -0.383143\n",
              "std             0.936908     0.115307  ...     0.635631     0.542258\n",
              "min            -2.353560     0.028571  ...    -2.535463    -1.652397\n",
              "25%            -1.105337     0.171429  ...    -0.977607    -0.714036\n",
              "50%            -0.306474     0.257143  ...    -0.491661    -0.436379\n",
              "75%             0.492389     0.342857  ...    -0.152790    -0.122801\n",
              "max             1.640755     0.685714  ...     0.646321     2.612347\n",
              "\n",
              "[8 rows x 19 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0wv4b_1IkIDo"
      },
      "source": [
        "# use the following lines only if you want to save the interpolated datasets\r\n",
        "df_train_scaled.to_csv(f'./interpolated_datasets/Karpos/train.csv', index=True)\r\n",
        "df_validation_scaled.to_csv(f'./interpolated_datasets/Karpos/validation.csv', index=True)\r\n",
        "df_test_scaled.to_csv(f'./interpolated_datasets/Karpos/test.csv', index=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YndtjJvdQjri"
      },
      "source": [
        "**Imputing missing values**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oivG5u94ksvu"
      },
      "source": [
        "This part should be done without previously interpolating the missing data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "89Hlit-Bb01w",
        "outputId": "d5ed1d55-5a4e-4ddf-8baf-caf397e8f744"
      },
      "source": [
        "missing_train = df_train_scaled.isna().sum().values\r\n",
        "missing_train_prob = missing_train / missing_train.sum()\r\n",
        "missing_train_prob"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.86219739e-03,\n",
              "       3.10366232e-04, 0.00000000e+00, 0.00000000e+00, 3.10366232e-04,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       6.70391061e-01, 1.96772191e-01, 1.30353818e-01])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 125
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "shIjE0fTQjPs"
      },
      "source": [
        "train_values = df_train_scaled.values.copy()\r\n",
        "validation_values = df_validation_scaled.values.copy()\r\n",
        "test_values = df_test_scaled.values.copy()\r\n",
        "validation_values_true = df_validation_scaled.dropna().values.copy()\r\n",
        "\r\n",
        "np.random.seed(0)\r\n",
        "validation_values_missing = validation_values_true.copy()\r\n",
        "n_samples, n_features = validation_values_missing.shape\r\n",
        "missing_samples = np.random.choice(n_samples, int(0.1*n_samples), replace=False)\r\n",
        "for s in missing_samples:\r\n",
        "  n_missing_features = np.random.randint(1, 5)\r\n",
        "  missing_features = np.random.choice(n_features, n_missing_features, replace=False, p=missing_train_prob)\r\n",
        "  validation_values_missing[s, missing_features] = np.nan"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nxEoqMEGRQ0a",
        "outputId": "f19d1415-63d2-4758-fab4-4bd286e7b0de"
      },
      "source": [
        "imputers = {'mean': SimpleImputer(missing_values=np.nan, strategy='mean'),\r\n",
        "            'median': SimpleImputer(missing_values=np.nan, strategy='median'),\r\n",
        "            'bayesian_ridge': IterativeImputer(estimator=BayesianRidge(), random_state=0),\r\n",
        "            'decision_tree': IterativeImputer(estimator=DecisionTreeRegressor(max_features='sqrt', random_state=0), random_state=0),\r\n",
        "            'k_neighbors_7': IterativeImputer(estimator=KNeighborsRegressor(n_neighbors=7), random_state=0, skip_complete=True),\r\n",
        "            'k_neighbors_11': IterativeImputer(estimator=KNeighborsRegressor(n_neighbors=11), random_state=0, skip_complete=True),\r\n",
        "            'k_neighbors_15': IterativeImputer(estimator=KNeighborsRegressor(n_neighbors=15), random_state=0, skip_complete=True),\r\n",
        "            'extra_trees_10': IterativeImputer(estimator=ExtraTreesRegressor(n_estimators=10, random_state=0), random_state=0, skip_complete=True),\r\n",
        "            'extra_trees_15': IterativeImputer(estimator=ExtraTreesRegressor(n_estimators=15, random_state=0), random_state=0, skip_complete=True),\r\n",
        "            'extra_trees_20': IterativeImputer(estimator=ExtraTreesRegressor(n_estimators=20, random_state=0), random_state=0, skip_complete=True)\r\n",
        "            }\r\n",
        "\r\n",
        "for imputer_name, imputer in imputers.items():\r\n",
        "  imputer.fit(train_values)\r\n",
        "  validation_values_filled = imputer.transform(validation_values_missing)\r\n",
        "  norm = np.linalg.norm(validation_values_true - validation_values_filled, ord='fro')\r\n",
        "  print(f'{imputer_name}:\\t\\t{norm}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mean:\t\t12.474401747314596\n",
            "median:\t\t12.655102572349586\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/impute/_iterative.py:638: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
            "  \" reached.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "bayesian_ridge:\t\t13.298130551688669\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/impute/_iterative.py:638: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
            "  \" reached.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "decision_tree:\t\t15.617717245396236\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/impute/_iterative.py:638: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
            "  \" reached.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "k_neighbors_7:\t\t12.406505319322077\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/impute/_iterative.py:638: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
            "  \" reached.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "k_neighbors_11:\t\t12.197414295570242\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/impute/_iterative.py:638: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
            "  \" reached.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "k_neighbors_15:\t\t12.094524532571054\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/impute/_iterative.py:638: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
            "  \" reached.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "extra_trees_10:\t\t13.709553608450967\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/impute/_iterative.py:638: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
            "  \" reached.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "extra_trees_15:\t\t14.043563220099912\n",
            "extra_trees_20:\t\t14.046359301036286\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/impute/_iterative.py:638: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
            "  \" reached.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qq4znfadq2MV"
      },
      "source": [
        "Based on the scores, K-Nearest Neighbors estimator with K=15 produced the best result for filling the missing values."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_QAAzCAkqVeQ",
        "outputId": "34862a19-6a05-4053-bd7c-b197656da576"
      },
      "source": [
        "imputer = imputers['k_neighbors_15']\r\n",
        "imputed_train_values = imputer.fit_transform(train_values)\r\n",
        "imputed_validation_values = imputer.transform(validation_values)\r\n",
        "imputed_test_values = imputer.transform(test_values)\r\n",
        "df_train_imputed = pd.DataFrame(data=imputed_train_values,\r\n",
        "                                index=df_train_scaled.index,\r\n",
        "                                columns=df_train_scaled.columns)\r\n",
        "df_validation_imputed = pd.DataFrame(data=imputed_validation_values,\r\n",
        "                                     index=df_validation_scaled.index,\r\n",
        "                                     columns=df_validation_scaled.columns)\r\n",
        "df_test_imputed = pd.DataFrame(data=imputed_test_values,\r\n",
        "                               index=df_test_scaled.index,\r\n",
        "                               columns=df_test_scaled.columns)\r\n",
        "df_train_imputed.to_csv(f'./preprocessed_datasets/Karpos/train.csv', index=True)\r\n",
        "df_validation_imputed.to_csv(f'./preprocessed_datasets/Karpos/validation.csv', index=True)\r\n",
        "df_test_imputed.to_csv(f'./preprocessed_datasets/Karpos/test.csv', index=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/impute/_iterative.py:638: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
            "  \" reached.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}